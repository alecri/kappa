Changes in Version 2.0-0 (2017-06-22)
=====================================

   o added simulate() method for 'rma' objects; added MASS to 'Suggests'
     (since simulating for 'rma.mv' objects requires mvrnorm() from MASS)

   o cooks.distance.rma.mv() now works properly even when there are missing
     values in the data

   o residuals() gains 'type' argument and can compute Pearson residuals

   o the 'newmods' argument in predict() can now be a named vector or a
     matrix/data frame with column names that get properly matched up with
     the variables in the model

   o added ranef.rma.mv() for extracting the BLUPs of the random effects for
     'rma.mv' models

   o all functions that repeatedly refit models now have the option to show
     a progress bar

   o added ranktest.default(), so user can now pass the outcomes and
     corresponding sampling variances directly to the function

   o added regtest.default(), so user can now pass the outcomes and
     corresponding sampling variances directly to the function

   o funnel.default() gains 'subset' argument

   o funnel.default() and funnel.rma() gain 'col' and 'bg' arguments

   o plot.profile.rma() gains 'ylab' argument

   o more consistent handling of 'robust.rma' objects

   o added location-scale model

   o added a print method for 'rma.gosh' objects

   o the (log) relative risk is now called the (log) risk ratio in all help
     files, plots, code, and comments

   o escalc() can now compute outcome measures based on paired binary data
     ("MPRR", "MPOR", "MPRD", "MPORC", and "MPPETO")

   o escalc() can now compute (semi-)partial correlation coefficients
     ("PCOR", "ZPCOR", "SPCOR")

   o escalc() can now compute measures of variability for single groups
     ("CVLN", "SDLN") and for the difference in variability between two
     groups ("CVR", "VR"); also the log transformed mean ("MNLN") has been
     added for consistency

   o escalc() can now compute the sampling variance for measure="PHI" for
     studies using stratified sampling (vtpye="ST")

   o the `[` method for 'escalc' objects now properly handles the 'ni' and
     'slab' attributes and does a better job of cleaning out superfluous
     variable name information

   o added rbind() method for 'escalc' objects

   o added as.data.frame() method for 'list.rma' objects

   o added a new dataset (dat.pagliaro1992) for another illustration of a
     network meta-analysis

   o added a new dataset (dat.laopaiboon2015) on the effectiveness of
     azithromycin for treating lower respiratory tract infections

   o rma.uni() and rma.mv() now check if the ratio of the largest to
     smallest sampling variance is extreme large; results may not be stable
     then (and very large ratios typically indicate wrongly coded data)

   o model fitting functions now check if extra/superfluous arguments are
     specified via ... and issues are warning if so

   o instead of defining own generic ranef(), import ranef() from 'nlme'

   o improved output formatting

   o added more tests (but disabled a few tests on CRAN to avoid some issues
     when R is compiled with --disable-long-double)

   o some general code cleanup

   o renamed diagram_metafor.pdf vignette to just diagram.pdf

   o minor updates in the documentation


Changes in Version 1.9-9 (2016-09-25)
=====================================

   o started to use git as version control system, GitHub to host the
     repository (https://github.com/wviechtb/metafor) for the development
     version of the package, Travis CI as continuous integration service
     (https://travis-ci.org/wviechtb/metafor), and Codecov for automated
     code coverage reporting (https://codecov.io/github/wviechtb/metafor)

   o argument 'knha' in rma.uni() and argument 'tdist' in rma.glmm() and
     rma.mv() are now superseded by argument 'test' in all three functions;
     for backwards compatibility, the 'knha' and 'tdist' arguments still
     work, but are no longer documented

   o rma(yi, vi, weights=1, test="knha") now yields the same results as
     rma(yi, vi, weighted=FALSE, test="knha") (but use of the Knapp and
     Hartung method in the context of an unweighted analysis remains an
     experimental feature)

   o one can now pass an 'escalc' object directly to rma.uni(), which then
     tries to automatically determine the 'yi' and 'vi' variables in the
     data frame (thanks to Christian Röver for the suggestion)

   o escalc() can now also be used to convert a regular data frame to an
     'escalc' object

   o for measure="UCOR", the exact bias-correction is now used (instead of
     the approximation); when vtype="UB", the exact equation is now used to
     compute the unbiased estimate of the variance of the bias-corrected
     correlation coefficient; hence 'gsl' is now a suggested package (needed
     to compute the hypergeometric function) and is loaded when required

   o cooks.distance() now also works with 'rma.mv' objects; and since model
     fitting can take some time, an option to show a progress bar has been
     added

   o fixed an issue with robust.rma.mv() throwing errors when the model was
     fitted with sparse=TRUE

   o fixed an error with robust.rma.mv() when the model was fitted with
     user-defined weights (or a user-defined weight matrix)

   o added ranef() for extracting the BLUPs of the random effects (only for
     'rma.uni' objects at the moment)

   o reverted back to the pre-1.1-0 way of computing p-values for individual
     coefficients in permutest.rma.uni(), that is, the p-value is computed
     with mean(abs(z_perm) >= abs(z_obs) - tol) (where 'tol' is a numerical
     tolerance)

   o permutest.rma.uni() gains 'permci' argument, which can be used to
     obtain permutation-based CIs of the model coefficients (note that this
     is computationally very demanding and may take a long time to complete)

   o rma.glmm() continues to work even when the saturated model cannot be
     fitted (although the tests for heterogeneity are not available then)

   o rma.glmm() now allows control over the arguments used for 'method.args'
     (via control=list(hessianCtrl=list(...))) passed to hessian() (from
     the 'numDeriv' package) when using model="CM.EL" and measure="OR"

   o in rma.glmm(), default 'method.args' value for 'r' passed to hessian()
     has been increased to 16 (while this slows things down a bit, this
     appears to improve the accuracy of the numerical approximation to the
     Hessian, especially when tau^2 is close to 0)

   o the various forest() and addpoly() functions now have a new argument
     called 'width', which provides manual control over the width of the
     annotation columns; this is useful when creating complex forest plots
     with a monospaced font and we want to ensure that all annotations are
     properly lined up at the decimal point

   o the annotations created by the various forest() and addpoly() functions
     are now a bit more compact by default

   o more flexible 'efac' argument in the various forest() functions

   o trailing zeros in the axis labels are now dropped in forest and funnel
     plots by default; but trailing zeros can be retained by specifying a
     numeric (and not an integer) value for the 'digits' argument

   o added funnel.default(), which directly takes as input a vector with the
     observed effect sizes or outcomes and the corresponding sampling
     variances, standard errors, and/or sample sizes

   o added plot.profile.rma(), a plot method for objects returned by the
     profile.rma.uni() and profile.rma.mv() functions

   o simplified baujat.rma.uni(), baujat.rma.mh(), and baujat.rma.peto() to
     baujat.rma(), which now handles objects of class 'rma.uni', 'rma.mh',
     and 'rma.peto'

   o baujat.rma() gains argument 'symbol' for more control over the plotting
     symbol

   o labbe() gains a 'grid' argument

   o more logical placement of labels in qqnorm.rma.uni(), qqnorm.rma.mh(),
     and qqnorm.rma.peto() functions (and more control thereof)

   o qqnorm.rma.uni() gains 'lty' argument

   o added gosh.rma() and plot.gosh.rma() for creating GOSH (i.e., graphical
     display of study heterogeneity) plots based on Olkin et al. (2012)

   o in the (rare) case where all observed outcomes are exactly equal to
     each other, test="knha" (i.e., knha=TRUE) in rma() now leads to more
     appropriate results

   o updated datasets so those containing precomputed effect size estimates
     or observed outcomes are already declared to be 'escalc' objects

   o added new datasets (dat.egger2001 and dat.li2007) on the effectiveness
     of intravenous magnesium in acute myocardial infarction

   o 'methods' package is now under 'Depends' (in addition to 'Matrix'), so
     that rma.mv(..., sparse=TRUE) always works, even under Rscript

   o some general code cleanup

   o added more tests (and used a more consistent naming scheme for tests)


Changes in Version 1.9-8 (2015-09-28)
=====================================

   o due to more stringent package testing, it is increasingly difficult to
     ensure that the package passes all checks on older versions of R; from
     now on, the package will therefore require, and be checked under, only
     the current (and the development) version of R

   o added graphics, grDevices, and methods to Imports (due to recent change
     in how CRAN checks packages)

   o the 'struct' argument for rma.mv() now also allows for "ID" and "DIAG",
     which are identical to the "CS" and "HCS" structures, but with the
     correlation parameter fixed to 0

   o added robust() for (cluster) robust tests and confidence intervals for
     'rma.uni' and 'rma.mv' models (this uses a robust sandwich-type
     estimator of the variance-covariance matrix of the fixed effects along
     the lines of the Eicker-Huber-White method)

   o confint() now works for models fitted with the rma.mv() function; for
     variance and correlation parameters, the function provides profile
     likelihood confidence intervals; the output generated by the confint()
     function has been adjusted in general to make the formatting more
     consistent across the different model types

   o for objects of class 'rma.mv', profile() now provides profile plots for
     all (non-fixed) variance and correlation components of the model when
     no component is specified by the user (via the sigma2, tau2, rho,
     gamma2, or phi arguments)

   o for measure="MD" and measure="ROM", one can now choose between
     vtype="LS" (the default) and vtype="HO"; the former computes the
     sampling variances without assuming homoscedasticity, while the latter
     assumes homoscedasticity

   o multiple model objects can now be passed to the fitstats(), AIC(), and
     BIC() functions

   o check for duplicates in the 'slab' argument is now done *after* any
     subsetting is done (as suggested by Michael Dewey)

   o rma.glmm() now again works when using add=0, in which case some of the
     observed outcomes (e.g., log odds or log odds ratios) may be NA

   o when using rma.glmm() with model="CM.EL", the saturated model (used to
     compute the Wald-type and likelihood ratio tests for the presence of
     (residual) heterogeneity) often fails to converge; the function now
     continues to run (instead of stopping with an error) and simply omits
     the test results from the output

   o when using rma.glmm() with model="CM.EL" and inversion of the Hessian
     fails via the Choleski factorization, the function now makes another
     attempt via the QR decomposition (even when this works, a warning is
     issued)

   o for rma.glmm(), BIC and AICc values were switched around; corrected

   o more use of suppressWarnings() is made when functions repeatedly need
     to fit the same model, such as cumul(), influence(), and profile();
     that way, one does not get inundated with the same warning(s)

   o some (overdue) updates to the documentation


Changes in Version 1.9-7 (2015-05-21)
=====================================

   o default optimizer for rma.mv() changed to nlminb() (instead of optim()
     with "Nelder-Mead"); extensive testing indicated that nlminb() (and
     also optim() with "BFGS") is typically quicker and more robust; note
     that this is in principle a non-backwards compatible change, but really
     a necessary one; and you can always revert to the old behavior with
     control=list(optimizer="optim", optmethod="Nelder-Mead")

   o all tests have been updated in accordance with the recommended syntax
     of the 'testthat' package; for example, expect_equivalent(x,y) is used
     instead of test_that(x, is_equivalent_to(y))

   o changed a few is_identical_to() comparisons to expect_equivalent()
     ones (that failed on Sparc Solaris)


Changes in Version 1.9-6 (2015-05-07)
=====================================

   o funnel() now works again for 'rma.glmm' objects (note to self: quit
     breaking things that work!)

   o rma.glmm() will now only issue a warning (and not an error) when the
     Hessian for the saturated model cannot be inverted (which is needed to
     compute the Wald-type test for heterogeneity, so the test statistic is
     then simply set to NA)

   o rma.mv() now allows for two terms of the form ~ inner | outer; the
     variance components corresponding to such a structure are called gamma2
     and correlations are called phi; other functions that work with objects
     of class 'rma.mv' have been updated accordingly

   o rma.mv() now provides (even) more optimizer choices: nlm() from the
     'stats' package, hjk() and nmk() from the 'dfoptim' package, and
     ucminf() from the 'ucminf' package; choose the desired optimizer via
     the control argument (e.g., control=list(optimizer="nlm"))

   o profile.rma.uni() and profile.rma.mv() now can do parallel processing
     (which is especially relevant for 'rma.mv' objects, where profiling is
     crucial and model fitting can be slow)

   o the various confint() functions now have a 'transf' argument (to apply
     some kind of transformation to the model coefficients and confidence
     interval bounds); coefficients and bounds for objects of class 'rma.mh'
     and 'rma.peto' are no longer automatically transformed

   o the various forest() functions no longer enforce that the actual x-axis
     limits ('alim') encompass the observed outcomes to be plotted; also,
     outcomes below or above the actual x-axis limits are no longer shown

   o the various forest() functions now provide control over the horizontal
     lines (at the top/bottom) that are automatically added to the plot via
     the 'lty' argument (this also allows for removing them); also, the
     vertical reference line is now placed *behind* the points/CIs

   o forest.default() now has argument 'col' which can be used to specify
     the color(s) to be used for drawing the study labels, points, CIs, and
     annotations

   o the 'efac' argument for forest.rma() now also allows two values, the
     first for the arrows and CI limits, the second for summary estimates

   o corrected some axis labels in various plots when measure="PLO"

   o axes in labbe() plots now have "(Group 1)" and "(Group 2)" added by
     default

   o anova.rma() gains argument 'L' for specifying linear combinations of
     the coefficients in the model that should be tested to be zero

   o in case removal of a row of data would lead to one or more inestimable
     model coefficients, baujat(), cooks.distance(), dfbetas(), influence(),
     and rstudent() could fail for 'rma.uni' objects; such cases are now
     handled properly

   o for models with moderators, the predict() function now shows the study
     labels when they have been specified by the user (and 'newmods' is not
     used)

   o if there is only one fixed effect (model coefficient) in the model, the
     print.infl.rma.uni() function now shows the DFBETAS values with the
     other case diagnostics in a single table (for easier inspection); if
     there is more than one fixed effect, a separate table is still used for
     the DFBETAS values (with one column for each coefficient)

   o added measure="SMCRH" to the escalc() function for the standardized
     mean change using raw score standardization with heteroscedastic
     population variances at the two measurement occasions

   o added measure="ROMC" to the escalc() function for the (log transformed)
     ratio of means (response ratio) when the means reflect two measurement
     occasions (e.g., for a single group of people) and hence are correlated

   o added own function for computing/estimating the tetrachoric correlation
     coefficient (for measure="RTET"); package therefore no longer suggests
     'polycor' but now suggest 'mvtnorm' (which is loaded as needed)

   o element 'fill' returned by trimfill.rma.uni() is now a logical vector
     (instead of a 0/1 dummy variable)

   o print.list.rma() now also returns the printed results invisibly as a
     data frame

   o added a new dataset (dat.senn2013) as another illustration of a network
     meta-analysis

   o metafor now depends on at least version 3.1.0 of R


Changes in Version 1.9-5 (2014-11-24)
=====================================

   o moved the 'stats' and 'Matrix' packages from 'Depends' to 'Imports'; as
     a result, had to add 'utils' to 'Imports'; moved the 'Formula' package
     from 'Depends' to 'Suggests'

   o added update.rma() function (for updating/refitting a model); model
     objects also now store and keep the call

   o the vcov() function now also extracts the marginal variance-covariance
     matrix of the observed effect sizes or outcomes from a fitted model
     (of class 'rma.uni' or 'rma.mv')

   o rma.mv() now makes use of the Cholesky decomposition when there is a
     'random = ~ inner | outer' formula and struct="UN"; this is numerically
     more stable than the old approach that avoided non-positive definite
     solutions by forcing the log-likelihood to be -Inf in those cases; the
     old behavior can be restored with 'control = list(cholesky=FALSE)'

   o rma.mv() now requires the 'inner' variable in an '~ inner | outer'
     formula to be a factor or character variable (except when 'struct' is
     "AR" or "HAR"); use '~ factor(inner) | outer' in case it isn't

   o anova.rma.uni() function changed to anova.rma() that works now for both
     'rma.uni' and 'rma.mv' objects

   o the profile.rma.mv() function now omits the number of the variance or
     correlation component from the plot title and x-axis label when the
     model only includes one of the respective parameters

   o profile() functions now pass on the ... argument also to the title()
     function used to create the figure titles (esp. relevant when using
     the 'cex.main' argument)

   o the 'drop00' argument of the rma.mh() and rma.peto() functions now also
     accepts a vector with two logicals, the first applies when calculating
     the observed outcomes, the second when applying the Mantel-Haenszel or
     Peto's method

   o weights.rma.uni() now shows the correct weights when weighted=FALSE

   o argument 'showweight' renamed to 'showweights' in the forest.default()
     and forest.rma() functions (more consistent with the naming of the
     various weights() functions)

   o added model.matrix.rma() function (to extract the model matrix from
     objects of class 'rma')

   o funnel() and radial() now (invisibly) return data frames with the
     coordinates of the points that were drawn (may be useful for manual
     labeling of points in the plots)

   o permutest.rma.uni() function now uses a numerical tolerance when making
     comparisons (>= or <=) between an observed test statistic and the test
     statistic under the permuted data; when using random permutations, the
     function now ensures that the very first permutation correspond to the
     original data

   o corrected some missing/redundant row/column labels in some output

   o most require() calls replaced with requireNamespace() to avoid altering
     the search path (hopefully this won't break stuff ...)

   o some non-visible changes including more use of some (non-exported)
     helper functions for common tasks

   o dataset dat.collins91985a updated (including all reported outcomes and
     some more information about the various trials)

   o oh, and guess what? I updated the documentation ...


Changes in Version 1.9-4 (2014-07-30)
=====================================

   o added method="GENQ" to rma.uni() for the generalized Q-statistic
     estimator of tau^2, which allows for used-defined weights (note: the DL
     and HE estimators are just special cases of this method)

   o when the model was fitted with method="GENQ", then confint() will now
     use the generalized Q-statistic method to construct the corresponding
     confidence interval for tau^2 (thanks to Dan Jackson for the code);
     the iterative method used to obtain the CI makes use of Farebrother's
     algorithm as implemented in the 'CompQuadForm' package

   o slight improvements in how the rma.uni() function handles non-positive
     sampling variances

   o rma.uni(), rma.mv(), and rma.glmm() now try to detect and remove any
     redundant predictors before the model fitting; therefore, if there are
     exact linear relationships among the predictor variables (i.e., perfect
     multicollinearity), terms are removed to obtain a set of predictors
     that is no longer perfectly multicollinear (a warning is issued when
     this happens); note that the order of how the variables are specified
     in the model formula can influence which terms are removed

   o the last update introduced an error in how hat values were computed
     when the model was fitted with the rma() function using the Knapp &
     Hartung method (i.e., when knha=TRUE); this has been fixed

   o regtest() no longer works (for now) with 'rma.mv' objects (it wasn't
     meant to in the first place); if you want to run something along the
     same lines, just consider adding some measure of the precision of the
     observed outcomes (e.g., their standard errors) as a predictor to the
     model

   o added "sqrtni" and "sqrtninv" as possible options for the 'predictor'
     argument of regtest()

   o more optimizers are now available for the rma.mv() function via the
     'nloptr' package by setting 'control = list(optimizer="nloptr")'; when
     using this optimizer, the default is to use the BOBYQA implementation
     from that package with a relative convergence criterion of 1e-8 on the
     function value (see documentation on how to change these defaults)

   o predict.rma() function now works for 'rma.mv' objects with multiple
     tau^2 values even if the user specifies the 'newmods' argument but not
     the 'tau2.levels' argument (but a warning is issued and the
     credibility/prediction intervals are not computed)

   o argument 'var.names' now works properly in escalc() when the user has
     not made use of the 'data' argument (thanks to Jarrett Byrnes for
     bringing this to my attention)

   o added plot() function for cumulative random-effects models results as
     obtained with the cumul.rma.uni() function; the plot shows the model
     estimate on the x-axis and the corresponding tau^2 estimate on the
     y-axis in the cumulative order of the results

   o fixed the omitted offset term in the underlying model fitted by the
     rma.glmm() function when method="ML", measure="IRR", and model="UM.FS",
     that is, when fitting a mixed-effects Poisson regression model with
     fixed study effects to two-group event count data (thanks to Peter
     Konings for pointing out this error)

   o added two new datasets (dat.bourassa1996, dat.riley2003)

   o added function replmiss() (just a useful helper function)

   o package now uses LazyData: TRUE

   o some improvements to the documentation (do I still need to mention this
     every time?)


Changes in Version 1.9-3 (2014-05-05)
=====================================

   o some minor tweaks to rma.uni() that should be user transparent

   o rma.uni() now has a 'weights' argument, allowing the user to specify
     arbitrary user-defined weights; all functions affected by this have
     been updated accordingly

   o better handling of mismatched length of yi and ni vectors in rma.uni()
     and rma.mv() functions

   o subsetting is now handled as early as possible within functions with
     subsetting capabilities; this avoids some (rare) cases where studies
     ultimately excluded by the subsetting could still affect the results

   o some general tweaks to rma.mv() that should make it a bit faster

   o argument 'V' of rma.mv() now also accepts a list of var-cov matrices
     for the observed effects or outcomes; from the list elements, the full
     (block diagonal) var-cov matrix V is then automatically constructed

   o rma.mv() now has a new argument 'W' allowing the user to specify
     arbitrary user-defined weights or an arbitrary weight matrix

   o rma.mv() now has a new argument 'sparse'; by setting this to true, the
     function uses sparse matrix objects to the extent possible; this can
     speed up model fitting substantially for certain models (hence, the
     'metafor' package now depends on the 'Matrix' package)

   o rma.mv() now allows for struct="AR" and struct="HAR", to fit models
     with (heteroscedastic) autoregressive (AR1) structures among the true
     effects (useful for meta-analyses of studies reporting outcomes at
     multiple time points)

   o rma.mv() now has a new argument 'Rscale' which can be used to control
     how matrices specified via the 'R' argument are scaled (see docs for
     more details)

   o rma.mv() now only checks for missing values in the rows of the lower
     triangular part of the V matrix (including the diagonal); this way, if
     Vi = matrix(c(.5,NA,NA,NA), nrow=2, ncol=2) is the var-cov matrix of
     the sampling errors for a particular study with two outcomes, then only
     the second row/column needs to be removed before the model fitting (and
     not the entire study)

   o added five new datasets (dat.begg1989, dat.ishak2007, dat.fine1993,
     dat.konstantopoulos2011, and dat.hasselblad1998) to provide further
     illustrations of the use of the rma.mv() function (for meta-analyses
     combining controlled and uncontrolled studies, for meta-analyses of
     longitudinal studies, for multilevel meta-analyses, and for network
     meta-analyses / mixed treatment comparison meta-analyses)

   o added rstandard.rma.mv() function to compute standardized residuals for
     models fitted with the rma.mv() function (rstudent.rma.mv() to be added
     at a later point); also added hatvalues.rma.mv() for computing the hat
     values and weights.rma.uni() for computing the weights (i.e., the
     diagonal elements of the weight matrix)

   o the various weights() functions now have a new argument 'type' to
     indicate whether only the diagonal elements of the weight matrix
     (default) or the entire weight matrix should be returned

   o the various hatvalues() functions now have a new argument 'type' to
     indicate whether only the diagonal elements of the hat matrix (default)
     or the entire hat matrix should be returned

   o predict.rma() function now works properly for 'rma.mv' objects (also
     has a new argument 'tau2.levels' to specify, where applicable, the
     levels of the inner factor when computing credibility/prediction
     intervals)

   o forest.rma() function now provides a bit more control over the color of
     the summary polygon and is now compatible with 'rma.mv' objects; also,
     has a new argument 'lty', which provides more control over the line
     type for the individual CIs and the credibility interval

   o addpoly.default() and addpoly.rma() now have a 'border' argument (for
     consistency with the forest.rma() function); addpoly.rma() now yields
     the correct CI bounds when the model was fitted with knha=TRUE

   o forest.cumul.rma() now provides the correct CI bounds when the models
     were fitted with the Knapp & Hartung method (i.e., when knha=TRUE in
     the original rma() function call)

   o the various forest() functions now return information about the chosen
     values for arguments xlim, alim, at, ylim, rows, cex, cex.lab, and
     cex.axis invisibly (useful for tweaking the default values); thanks to
     Michael Dewey for the suggestion

   o the various forest() functions now have a new argument, clim, to set
     limits for the confidence/credibility/prediction interval bounds

   o cumul.mh() and cumul.peto() now get the order of the studies right when
     there are missing values in the data

   o the 'transf' argument of leave1out.rma.mh(), leave1out.rma.peto(),
     cumul.rma.mh(), and cumul.rma.peto() should now be used to specify the
     actual function for the transformation (the former behavior of setting
     this argument to TRUE to exponentiate log RRs, log ORs, or log IRRs
     still works for back-compatibility); this is more consistent with how
     the cumul.rma.uni() and leave1out.rma.uni() functions work and is also
     more flexible

   o added bldiag() function to construct a block diagonal matrix from (a
     list of) matrices (may be needed to construct the V matrix when using
     the rma.mv() function); bdiag() function from the 'Matrix' package does
     the same thing, but creates sparse matrix objects

   o profile.rma.mv() now has a 'startmethod' argument; by setting this to
     "prev", successive model fits are started at the parameter estimates
     from the previous model fit; this may speed things up a bit; also, the
     method for automatically choosing the xlim values has been changed

   o slight improvement to profile.rma.mv() function, which would throw an
     error if the last model fit did not converge

   o added a new dataset (dat.linde2005) for replication of the analyses in
     Viechtbauer (2007)

   o added a new dataset (dat.molloy2014) for illustrating the meta-analysis
     of (r-to-z transformed) correlation coefficients

   o added a new dataset (dat.gibson2002) to illustrate the combined
     analysis of standardized mean differences and probit transformed risk
     differences

   o computations in weights.mh() slightly changed to prevent integer
     overflows for large counts

   o unnecessary warnings in transf.ipft.hm() are now suppressed (cases that
     raised those warnings were already handled correctly)

   o in predict(), blup(), cumul(), and leave1out(), when using the 'transf'
     argument, the standard errors (which are NA) are no longer shown in the
     output

   o argument 'slab' in various functions will now also accept non-unique
     study labels; make.unique() is used as needed to make them unique

   o vignettes("metafor") and vignettes("metafor_diagram") work again (yes,
     I know they are not true vignettes in the strict sense, but I think
     they should show up on the CRAN website for the package and using a
     minimal valid Sweave document that is recognized by the R build system
     makes that happen)

   o escalc() and its summary() method now keep better track when the data
     frame contains multiple columns with outcome or effect size values (and
     corresponding sampling variances) for print formatting; also simplified
     the class structure a bit (and hence, print.summary.escalc() removed)

   o summary.escalc() has a new argument 'H0' to specify the value of the
     outcome under the null hypothesis for computing the test statistics

   o added measures "OR2DN" and "D2ORN" to escalc() for transforming log
     odds ratios to standardized mean differences and vice-versa, based on
     the method of Cox & Snell (1989), which assumes normally distributed
     response variables within the two groups before the dichotomization

   o permutest.rma.uni() function now catches an error when the number of
     permutations requested is too large (for R to even create the objects
     to store the results in) and produces a proper error message

   o funnel.rma() function now allows the 'yaxis' argument to be set to "wi"
     so that the actual weights (in %) are placed on the y-axis (useful when
     arbitrary user-defined have been specified)

   o for rma.glmm(), the control argument 'optCtrl' is now used for passing
     control arguments to all of the optimizers (hence, control arguments
     nlminbCtrl and minqaCtrl are now defunct)

   o rma.glmm() should not throw an error anymore when including only a
     single moderator/predictor in the model

   o predict.rma() now returns an object of class 'list.rma' (therefore,
     function print.predict.rma() has been removed)

   o for 'rma.list' objects, added `[`, head(), and tail() methods

   o automated testing using the 'testthat' package (still many more tests
     to add, but finally made a start on this)

   o encoding changed to UTF-8 (to use 'foreign characters' in the docs and
     to make the HTML help files look a bit nicer)

   o guess what? some improvements to the documentation! (also combined some
     of the help files to reduce the size of the manual a bit; and yes, it's
     still way too big)


Changes in Version 1.9-2 (2013-10-07)
=====================================

   o added function rma.mv() to fit multivariate/multilevel meta-analytic
     models via appropriate linear (mixed-effects) models; this function
     allows for modeling of non-independent sampling errors and/or true
     effects and can be used for network meta-analyses, meta-analyses
     accounting for phylogenetic relatedness, and other complicated
     meta-analytic data structures

   o added the AICc to the information criteria computed by the various
     model fitting functions

   o if the value of tau^2 is fixed by the user via the corresponding
     argument in rma.uni(), then tau^2 is no longer counted as an additional
     parameter for the computation of the information criteria (i.e., AIC,
     BIC, and AICc)

   o rma.uni(), rma.glmm(), and rma.mv() now use a more stringent check
     whether the model matrix is of full rank

   o added profile() method functions for objects of class 'rma.uni' and
     'rma.mv' (can be used to obtain a plot of the profiled log-likelihood
     as a function of a specific variance component or correlation parameter
     of the model)

   o predict.rma() function now has an 'intercept' argument that allows the
     user to decide whether the intercept term should be included when
     calculating the predicted values (rare that this should be changed from
     the default)

   o for rma.uni(), rma.glmm(), and rma.mv(), the 'control' argument can now
     also accept an integer value; values > 1 generate more verbose output
     about the progress inside of the function

   o rma.glmm() has been updated to work with lme4 1.0.x for fitting various
     models; as a result, model="UM.RS" can only use nAGQ=1 at the moment
     (hopefully this will change in the future)

   o the 'control' argument of rma.glmm() can now be used to pass all
     desired control arguments to the various functions and optimizers used
     for the model fitting (admittedly the use of lists within this argument
     is a bit unwieldy, but much more flexible)

   o rma.mh() and rma.peto() also now have a 'verbose' argument (not really
     needed, but added for sake of consistency across functions)

   o fixed (silly) error that would prevent rma.glmm() from running for
     measures "IRR", "PLO", and "IRLN" when there are missing values in the
     data (lesson: add some missing values to datasets for the unit tests!)

   o a bit of code reorganization (should be user transparent)

   o vignettes ("metafor" and "metafor_diagram") are now just 'other files'
     in the doc directory (as these were not true vignettes to begin with)

   o some improvements to the documentation (as always)


Changes in Version 1.9-1 (2013-07-20)
=====================================

   o rma.mh() now also implements the Mantel-Haenszel method for incidence
     rate differences (measure="IRD")

   o when analyzing incidence rate ratios (measure="IRR") with the rma.mh()
     function, the Mantel-Haenszel test for person-time data is now also
     provided

   o rma.mh() has a new argument 'correct' (default is TRUE) to indicate
     whether the continuity correction should be applied when computing the
     (Cochran-)Mantel-Haenszel test statistic

   o renamed elements 'CMH' and 'CMHp' (for the Cochran-Mantel-Haenszel test
     statistic and corresponding p-value) to 'MH' and 'MHp'

   o added function baujat() to create Baujat plots

   o added a new dataset (dat.pignon2000) to illustrate the use of the
     baujat() function

   o added function to.table() to convert data from vector format into the
     corresponding table format

   o added function to.long() to convert data from vector format into the
     corresponding long format

   o rma.glmm() now even runs when k=1 (yielding trivial results)

   o for models with an intercept and moderators, rma.glmm() now internally
     rescales (non-dummy) variables to z-scores during the model fitting
     (this improves the stability of the model fitting, especially when
     model="CM.EL"); results are given after back-scaling, so this should
     be transparent to the user

   o in rma.glmm(), default number of quadrature points (nAGQ) is now 7
     (setting this to 100 was a bit overkill)

   o a few more error checks here and there for misspecified arguments

   o some improvements to the documentation


Changes in Version 1.9-0 (2013-06-21)
=====================================

   o vignette renamed to 'metafor' so vignette("metafor") works now

   o added a diagram to the documentation, showing the various functions in
     the metafor package (and how they relate to each other); can be loaded
     with vignette("metafor_diagram")

   o anova.rma.uni() function can now also be used to test (sub)sets of
     model coefficients with a Wald-type test when a single model is passed
     to the function

   o the pseudo R^2 statistic is now automatically calculated by the
     rma.uni() function and supplied in the output (only for mixed-effects
     models and when the model includes an intercept, so that the random-
     effects model is clearly nested within the mixed-effects model)

   o component 'VAF' is now called 'R2' in anova.rma.uni() function

   o added function hc() that carries out a random-effects model analysis
     using the method by Henmi and Copas (2010); thanks to Michael Dewey for
     the suggestion and providing the code

   o added new dataset (dat.lee2004), which was used in the article by Henmi
     and Copas (2010) to illustrate their method

   o fixed missing x-axis labels in the forest() functions

   o rma.glmm() now computes Hessian matrices via the 'numDeriv' package
     when model="CM.EL" and measure="OR" (i.e., for the conditional logistic
     model with exact likelihood); so 'numDeriv' is now a suggested package
     and is loaded within rma.glmm() when required

   o trimfill.rma.uni() now also implements the "Q0" estimator (although the
     "L0" and "R0" estimators are generally to be preferred)

   o trimfill.rma.uni() now also calculates the SE of the estimated number
     of missing studies and, for estimator "R0", provides a formal test of
     the null hypothesis that the number of missing studies on a given side
     is zero

   o added new dataset (dat.bangertdrowns2004)

   o the 'level' argument in various functions now either accepts a value
     representing a percentage or a proportion (values greater than 1 are
     assumed to be a percentage)

   o summary.escalc() now computes confidence intervals correctly when using
     the 'transf' argument

   o computation of Cochran-Mantel-Haenszel statistic in rma.mh() changed
     slightly to avoid integer overflow with very big counts

   o some internal improvements with respect to object attributes that were
     getting discarded when subsetting

   o some general code cleanup

   o some improvements to the documentation


Changes in Version 1.8-0 (2013-04-11)
=====================================

   o added additional clarifications about the change score outcome measures
     ("MC", "SMCC", and "SMCR") to the help file for the escalc() function
     and changed the code so that "SMCR" no longer expects argument 'sd2i'
     to be specified (which is not needed anyways) (thanks to Markus Kösters
     for bringing this to my attention)

   o sampling variance for the biserial correlation coefficient ("RBIS") is
     now calculated in a slightly more accurate way

   o llplot() now properly scales the log-likelihoods

   o argument 'which' in the plot.infl.rma.uni() function has been replaced
     with argument 'plotinf' which can now also be set to FALSE to suppress
     plotting of the various case diagnostics altogether

   o labeling of the axes in labbe() plots is now correct for odds ratios
     (and transformations thereof)

   o added two new datasets (dat.nielweise2007 and dat.nielweise2008) to
     illustrate some methods/models from the rma.glmm() function

   o added a new dataset (dat.yusuf1985) to illustrate the use of rma.peto()

   o test for heterogeneity is now conducted by the rma.peto() function
     exactly as described by Yusuf et al. (1985)

   o in rma.glmm(), default number of quadrature points (nAGQ) is now 100
     (which is quite a bit slower, but should provide more than sufficient
     accuracy in most cases)

   o the standard errors of the HS and DL estimators of tau^2 are now
     correctly computed when tau^2 is prespecified by the user in the rma()
     function; in addition, the standard error of the SJ estimator is also
     now provided when tau^2 is prespecified

   o rma.uni() and rma.glmm() now use a better method to check whether the
     model matrix is of full rank

   o I^2 and H^2 statistics are now also calculated for mixed-effects models
     by the rma.uni() and rma.glmm() function; confint.rma.uni() provides
     the corresponding confidence intervals for rma.uni() models

   o various print() methods now have a new argument called 'signif.stars',
     which defaults to getOption("show.signif.stars") (which by default is
     TRUE) to determine whether the infamous 'significance stars' should be
     printed

   o slight changes in wording in the output produced by the print.rma.uni()
     and print.rma.glmm() functions

   o some improvements to the documentation


Changes in Version 1.7-0 (2013-02-06)
=====================================

   o added rma.glmm() function for fitting of appropriate generalized linear
     (mixed-effects) models when analyzing odds ratios, incidence rate
     ratios, proportions, or rates; the function makes use of the 'lme4' and
     'BiasedUrn' packages; these are now suggested packages and loaded
     within rma.glmm() only when required (this makes for faster loading of
     the 'metafor' package)

   o added several methods functions for objects of class 'rma.glmm' (not
     all methods yet implemented; to be completed in the future)

   o rma.uni() now allows the user to specify a formula for the 'yi'
     argument, so instead of rma(yi, vi, mods=~mod1+mod2), one can specify
     the same model with rma(yi~mod1+mod2, vi)

   o rma.uni() now has a 'weights' argument to specify the inverse of the
     sampling variances (instead of using the 'vi' or 'sei' arguments); for
     now, this is all this argument should be used for (in the future, this
     argument may potentially be used to allow the user to define
     alternative weights)

   o rma.uni() now checks whether the model matrix is not of full rank and
     issues an error accordingly (instead of the rather cryptic error that
     was issued before)

   o rma.uni() now has a 'verbose' argument

   o coef.rma() now returns only the model coefficients (this change was
     necessary to make the package compatible with the 'multcomp' package;
     see help(rma) for an example); use coef(summary()) to obtain the full
     table of results

   o the escalc() function now does some more extensive error checking for
     misspecified data and some unusual cases

   o 'append' argument is now TRUE by default in the escalc() function

   o objects generated by the escalc() function now have their own class

   o added print() and summary() methods for objects of class 'escalc'

   o added `[` and cbind() methods for objects of class 'escalc'

   o added a few additional arguments to the escalc() function (i.e., slab,
     subset, var.names, replace, digits)

   o added 'drop00' argument to the escalc(), rma.uni(), rma.mh(), and
     rma.peto() functions

   o added "MN", "MC", "SMCC", and "SMCR" measures to the escalc() and
     rma.uni() functions for the raw mean, the raw mean change, and the
     standardized mean change (with change score or raw score
     standardization) as possible outcome measures

   o the "IRFT" measure in the escalc() and rma.uni() functions is now
     computed with 1/2*(sqrt(xi/ti) + sqrt(xi/ti+1/ti)) which is more
     consistent with the definition of the Freeman-Tukey transformation for
     proportions

   o added "RTET" measure to the escalc() and rma.uni() functions to compute
     the tetrachoric correlation coefficient based on 2x2 table data (the
     'polycor' package is therefore now a suggested package, which is loaded
     within escalc() only when required)

   o added "RPB" and "RBIS" measures to the escalc() and rma.uni() functions
     to compute the point-biserial and biserial correlation coefficient
     based on means and standard deviations

   o added "PBIT" and "OR2D" measures to the escalc() and rma.uni()
     functions to compute the standardized mean difference based on 2x2
     table data

   o added the "D2OR" measure to the escalc() and rma.uni() functions to
     compute the log odds ratio based on the standardized mean difference

   o added "SMDH" measure to the escalc() and rma.uni() functions to compute
     the standardized mean difference without assuming equal population
     variances

   o added "ARAW", "AHW", and "ABT" measures to the escalc() and rma.uni()
     functions for the raw value of Cronbach's alpha, the transformation
     suggested by Hakstian & Whalen (1976), and the transformation suggested
     by Bonett (2002) for the meta-analysis of reliability coefficients (see
     help(escalc) for details)

   o corrected a small mistake in the equation used to compute the sampling
     variance of the phi coefficient (measure="PHI") in the escalc()
     function

   o the permutest.rma.uni() function now uses an algorithm to find only the
     unique permutations of the model matrix (which may be much smaller
     than the total number of permutations), making the exact permutation
     test feasible in a larger set of circumstances (thanks to John Hodgson
     for making me aware of this issue and to Hans-Jörg Viechtbauer for
     coming up with a recursive algorithm for finding the unique
     permutations)

   o credibility interval in forest.rma() is now indicated with a dotted
     (instead of a dashed) line; ends of the interval are now marked with
     vertical bars

   o completely rewrote the funnel.rma() function which now supports many
     more options for the values to put on the y-axis; trimfill.rma.uni()
     function was adapted accordingly

   o removed the 'ni' argument from the regtest.rma() function; instead,
     sample sizes can now be explicitly specified via the 'ni' argument when
     using the rma.uni() function (i.e., when measure="GEN"); the escalc()
     function also now adds information on the 'ni' values to the resulting
     data frame (as an attribute of the 'yi' variable), so, if possible,
     this information is passed on to regtest.rma()

   o added switch so that regtest() can also provide the full results from
     the fitted model (thanks to Michael Dewey for the suggestion)

   o weights.rma.mh() now shows the weights in % as intended (thanks to
     Gavin Stewart for pointing out this error)

   o more flexible handling of the 'digits' argument in the various forest
     functions

   o forest functions now use pretty() by default to set the x-axis tick
     locations ('alim' and 'at' arguments can still be used for complete
     control)

   o studies that are considered to be 'influential' are now marked with an
     asterisk when printing the results returned by the influence.rma.uni()
     function (see the documentation of this function for details on how
     such studies are identified)

   o added additional extractor functions for some of the influence measures
     (i.e., cooks.distance, dfbetas); unfortunately, the 'covratio' and
     'dffits' functions in the 'stats' package are not generic; so, to avoid
     masking, there are currently no extractor functions for these measures

   o better handling of missing values in some unusual situations

   o corrected small bug in fsn() that would not allow the user to specify
     the standard errors instead of the sampling variances (thanks to Bernd
     Weiss for pointing this out)

   o plot.infl.rma.uni() function now allows the user to specify which plots
     to draw (and the layout) and adds the option to show study labels on
     the x-axis

   o added proper print() method for objects generated by the
     confint.rma.uni(), confint.mh(), and confint.peto() functions

   o when 'transf' or 'atransf' argument was a monotonically *decreasing*
     function, then confidence, prediction, and credibility interval bounds
     were in reversed order; various functions now check for this and order
     the bounds correctly

   o trimfill.rma.uni() now only prints information about the number of
     imputed studies when actually printing the model object

   o qqnorm.rma.uni(), qqnorm.rma.mh(), and qqnorm.rma.peto() functions now
     have a new argument called 'label', which allows for labeling of
     points; the functions also now return (invisibly) the x and y
     coordinates of the points drawn

   o rma.mh() with measure="RD" now computes the standard error of the
     estimated risk difference based on Sato, Greenland, & Robins (1989),
     which provides a consistent estimate under both large-stratum and
     sparse-data limiting models

   o the restricted maximum likelihood (REML) is now calculated using the
     full likelihood equation (without leaving out additive constants)

   o the model deviance is now calculated as -2 times the difference between
     the model log-likelihood and the log-likelihood under the saturated
     model (this is a more appropriate definition of the deviance than just
     taking -2 times the model log-likelihood)

   o naming scheme of illustrative datasets bundled with the package has
     been changed; now datasets are called <dat.authoryear>; therefore, the
     datasets are now called (old name -> new name):
     * dat.bcg      -> dat.colditz1994
     * dat.warfarin -> dat.hart1999
     * dat.los      -> dat.normand1999
     * dat.co2      -> dat.curtis1998
     * dat.empint   -> dat.mcdaniel1994

   o but dat.bcg has been kept as an alias for dat.colditz1994, as it has
     been referenced under that name in some publications

   o added new dataset (dat.pritz1997) to illustrate the meta-analysis of
     proportions (raw values and transformations thereof)

   o added new dataset (dat.bonett2010) to illustrate the meta-analysis of
     Cronbach's alpha values (raw values and transformations thereof)

   o added new datasets (dat.hackshaw1998, dat.raudenbush1985)

   o (approximate) standard error of the tau^2 estimate is now computed and
     shown for most of the (residual) heterogeneity estimators

   o added nobs() and df.residual() methods for objects of class 'rma'

   o metafor.news() is now simply a wrapper for news(package="metafor")

   o the package code is now byte-compiled, which yields some modest
     increases in execution speed

   o some general code cleanup

   o the 'metafor' package no longer depends on the 'nlme' package

   o some improvements to the documentation


Changes in Version 1.6-0 (2011-04-13)
=====================================

   o trimfill.rma.uni() now returns a proper object even when the number of
     missing studies is estimated to be zero

   o added the (log transformed) ratio of means as a possible outcome
     measure to the escalc() and rma.uni() functions (measure="ROM")

   o added new dataset (dat.co2) to illustrate the use of the ratio of means
     outcome measure

   o some additional error checking in the various forest functions
     (especially when using the 'ilab' argument)

   o in labbe.rma(), the solid and dashed lines are now drawn behind (and
     not on top of) the points

   o slight change to transf.ipft.hm() so that missing values in 'targs$ni'
     are ignored

   o some improvements to the documentation


Changes in Version 1.5-0 (2010-12-16)
=====================================

   o the 'metafor' package now has its own project website at:
     http://www.metafor-project.org/

   o added labbe() function to create LAbbe plots

   o the forest.default() and addpoly.default() functions now allow the user
     to directly specify the lower and upper confidence interval bounds
     (this can be useful when the CI bounds have been calculated with other
     methods/functions)

   o added the incidence rate for a single group and for two groups (and
     transformations thereof) as possible outcome measures to the escalc()
     and rma.uni() functions (measure="IRR", "IRD", "IRSD", "IR", "IRLN",
     "IRS", and "IRFT")

   o added the incidence rate ratio as a possible outcome measure to the
     rma.mh() function

   o added transformation functions related to incidence rates

   o added the Freeman-Tukey double arcsine transformation and its inverse
     to the transformation functions

   o added some additional error checking for out-of-range p-values in the
     permutest.rma.uni() function

   o added some additional checking for out-of-range values in several
     transformation functions

   o added confint() methods for 'rma.mh' and 'rma.peto' objects (only for
     completeness sake; print already provides CIs)

   o added new datasets (dat.warfarin, dat.los, dat.empint)

   o some improvements to the documentation


Changes in Version 1.4-0 (2010-07-31)
=====================================

   o a papar about the package has now been published in the Journal of
     Statistical Software (http://www.jstatsoft.org/v36/i03/)

   o added citation info; see: citation("metafor")

   o the 'metafor' package now depends on the 'nlme' package

   o added extractor functions for the AIC, BIC, and deviance

   o some updates to the documentation


Changes in Version 1.3-0 (2010-06-25)
=====================================

   o the 'metafor' package now depends on the 'Formula' package

   o made escalc() generic and implemented a default and a formula interface

   o added the (inverse) arcsine transformation to the set of transformation
     functions


Changes in Version 1.2-0 (2010-05-18)
=====================================

   o cases where k is very small (e.g., k equal to 1 or 2) are now handled
     more gracefully

   o added sanity check for cases where all observed outcomes are equal to
     each other (this led to division by zero when using the Knapp &
     Hartung method)

   o the "smarter way to set the number of iterations for permutation tests"
     (see notes for previous version below) now actually works like it is
     supposed to

   o the permutest.rma.uni() function now provides more sensible results
     when k is very small; the documentation for the function has also been
     updated with some notes about the use of permutation tests under those
     circumstances

   o made some general improvements to the various forest plot functions
     making them more flexible in particular when creating more complex
     displays; most importantly, added a 'rows' argument and removed the
     'addrows' argument

   o some additional examples have been added to the help files for the
     forest and addpoly functions to demonstrate how to create more complex
     displays with these functions

   o added 'showweight' argument to the forest.default() and forest.rma()
     functions

   o cumul() functions not showing all of the output columns when using
     fixed-effects models has been corrected

   o weights.rma.uni() function now handles NAs appropriately

   o weights.rma.mh() and weights.rma.peto() functions added

   o logLik.rma() function now behaves more like other logLik() functions
     (such as logLik.lm() and logLik.lme())


Changes in Version 1.1-0 (2010-04-28)
=====================================

   o cint() generic removed and replaced with confint() method for objects
     of class 'rma.uni'

   o slightly improved the code to set the x-axis title in the forest() and
     funnel() functions

   o added coef() method for 'permutest.rma.uni' objects

   o added 'append' argument to escalc() function

   o implemented a smarter way to set the number of iterations for
     permutation tests (i.e., the permutest.rma.uni() function will now
     switch to an exact test if the number of iterations required for an
     exact test is actually smaller than the requested number of iterations
     for an approximate test)

   o changed the way how p-values for individual coefficients are calculated
     in permutest.rma.uni() to 'two times the one-tailed area under the
     permutation distribution' (more consistent with the way we typically
     define two-tailed p-values)

   o added 'retpermdist' argument to permutest.rma.uni() to return the
     permutation distributions of the test statistics

   o slight improvements to the various transformation functions to cope
     better with some extreme cases

   o p-values are now calculated in such a way that very small p-values
     stored in fitted model objects are no longer truncated to 0 (the
     printed results are still truncated depending on the number of digits
     specified)

   o changed the default number of iterations for the ML, REML, and EB
     estimators from 50 to 100


Changes in Version 1.0-1 (2010-02-02)
=====================================

   o version jump in conjunction with the upcoming publication of a paper in
     the Journal of Statistical Software describing the 'metafor' package

   o instead of specifying a model matrix, the user can now specify a model
     formula for the 'mods' argument in the rma() function (e.g., like in
     the lm() function)

   o permutest() function now allows exact permutation tests (but this is
     only feasible when k is not too large)

   o forest() function now uses the 'level' argument properly to adjust the
     CI level of the summary estimate for models without moderators (i.e.,
     for fixed- and random-effets models)

   o forest() function can now also show the credibility interval as a
     dashed line for a random-effects model

   o information about the measure used is now passed on to the forest() and
     funnel() functions, which try to set an appropriate x-axis title
     accordingly

   o funnel() function now has more arguments (e.g., atransf, at) providing
     more control over the display of the x-axis

   o predict() function now has its own print() method and has a new
     argument called 'addx', which adds the values of the moderator
     variables to the returned object (when addx=TRUE)

   o functions now properly handle the na.action "na.pass" (treated
     essentially like "na.exclude")

   o added method for weights() to extract the weights used when fitting
     models with rma.uni()

   o some small improvements to the documentation


Changes in Version 0.5-7 (2009-12-06)
=====================================

   o added permutest() function for permutation tests

   o added metafor.news() function to display the NEWS file of the 'metafor'
     package within R (based on same idea in the 'animate' package by Yihui
     Xie)

   o added some checks for values below machine precision

   o a bit of code reorganization (nothing that affects how the functions
     work)


Changes in Version 0.5-6 (2009-10-19)
=====================================

   o small changes to the computation of the DFFITS and DFBETAS values in
     the influence() function, so that these statistics are more in line
     with their definitions in regular linear regression models

   o added option to the plot function for objects returned by influence()
     to allow plotting the covariance ratios on a log scale (now the
     default)

   o slight adjustments to various print() functions (to catch some errors
     when certain values were NA)

   o added a control option to rma() to adjust the step length of the Fisher
     scoring algorithm by a constant factor (this may be useful when the
     algorithm does not converge)


Changes in Version 0.5-5 (2009-10-08)
=====================================

   o added the phi coefficient (measure="PHI"), Yule's Q ("YUQ"), and Yule's
     Y ("YUY") as additional measures to the escalc() function for 2x2 table
     data

   o forest plots now order the studies so that the first study is at the
     top of the plot and the last study at the bottom (the order can still
     be set with the 'order' or 'subset' argument)

   o added cumul() function for cumulative meta-analyses (with a
     corresponding forest() method to plot the cumulative results)

   o added leave1out() function for leave-one-out diagnostics

   o added option to qqnorm.rma.uni() so that the user can choose whether to
     apply the Bonferroni correction to the bounds of the pseudo confidence
     envelope

   o some internal changes to the class and methods names

   o some small corrections to the documentation


Changes in Version 0.5-4 (2009-09-18)
=====================================

   o corrected the trimfill() function

   o improvements to various print functions

   o added a regtest() function for various regression tests of funnel plot
     asymmetry (e.g., Egger's regression test)

   o made ranktest() generic and added a method for objects of class 'rma'
     so that the test can be carried out after fitting

   o added anova() function for full vs reduced model comparisons via fit
     statistics and likelihood ratio tests

   o added the Orwin and Rosenberg approaches to fsn()

   o added H^2 measure to the output for random-effects models

   o in escalc(), measure="COR" is now used for the (usual) raw correlation
     coefficient and measure="UCOR" for the bias corrected correlation
     coefficients

   o some small corrections to the documentation


Changes in Version 0.5-3 (2009-07-31)
=====================================

   o small changes to some of the examples

   o added the log transformed proportion (measure="PLN") as another
     measure to the escalc() function; changed "PL" to "PLO" for the logit
     (i.e., log odds) transformation for proportions


Changes in Version 0.5-2 (2009-07-06)
=====================================

   o added an option in plot.infl.rma.uni() to open a new device for
     plotting the DFBETAS values

   o thanks to Jim Lemon, added a much better method for adjusting the size
     of the labels, annotations, and symbols in the forest() function when
     the number of studies is large


Changes in Version 0.5-1 (2009-06-14)
=====================================

   o made some small changes to the documentation (some typos corrected,
     some confusing points clarified)


Changes in Version 0.5-0 (2009-06-05)
=====================================

   o first version released on CRAN
