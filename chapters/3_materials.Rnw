% !TeX root = ../kappa.Rnw  


% ---------------------------------------------------------
% Project: PhD KAPPA
% File: materials.tex
% Author: Alessio Crippa
% based on the template written by Andrea Discacciati
%
% Purpose: Materials
% ---------------------------------------------------------

\chapter{Methods}

\section{The \pkg{dosresmeta} \textsf{R} package}

The first version of the \pkg{dosresmeta} \textsf{R} package was released on the Comprehensive R Archive Network (CRAN) on September 9, 2013. It is listed in the CRAN task view Meta-Analysis (\url{https://CRAN.R-project.org/view=MetaAnalysis}), a guide that covers the vast collection of \textsf{R} packages for facilitating meta-analysis of summary statistics.
New features and some minor bug fixes were implemented in further versions, including the major release (2.0.0 version) in August 17, 2017. The implementation of the package is presented in \citetalias{crippa2016dosresmeta}, which is also offered as a free guide for the package in a vignette accessible by typing \texttt{browseVignettes("dosresmeta")} from the \textsf{R} console.

\subsection{Implementation}

The initial version 1.0 of the \pkg{dosresmeta} \textsf{R} package implemented the two-stage approach for dose--response meta-analysis described in sections~\ref{sec:1st_stage} and~\ref{sec:2nd_stage}. The package included some facilities for efficiently estimating the dose--response associations across the included studies and used the \pkg{mvmeta} package for combining the study-specific regression coefficients \citep{gasparrini2012multivariate}. The main novelty of the version 1.0 was the implementation of \texttt{gl} and \texttt{hamling} functions for reconstructing the covariance matrices among set of log relative risks using the methods developed by \cite{greenland1992methods} and \cite{hamling2008facilitating}. 
In version 1.3 dedicated functions were dedicated for summarizing and displaying results, and for predicting the pooled dose--response association as described in section~\ref{sec:pred}. Compared to other routines, the \texttt{predict} function offers the possibility of deriving the predicted curve also for dose levels that are not observed in the analyzed data. The same applies for the choice of the reference dose value. The main advantage is that nice curves and tables including combined results for desired dose value can be easily obtained with a few lines of code. Practical examples are still available at \url{https://alecri.github.io/software/dosresmeta.html}.
In addition, the \texttt{center} argument was added in the main function for centering the design matrix as described by \cite{liu2009two}. The argument has been set to \texttt{TRUE} by default for preventing possible errors when modelling non-linear curves, especially in case of non-zero exposure reference categories. Finally, additional arguments were introduced for allowing the specification of a list of covariance matrices directly by the user.

\noindent New capabilities and functions were written in the version under development available on GitHub and were finally included in the major release version 2.0 on CRAN. The \pkg{dosresmeta} package was largely redesigned in the internal functions but kept unchanged the external form and arguments for backward compatibility. Three main features were introduced: the extension of the two-stage approach for dose--response meta-analysis of differences in means (rather than log relative risks) \citep{crippa2016dose}, the  possibility of fitting meta-regression models and the implementation of an alternative one-stage approach. The first was achieved by extending the choices of the \texttt{covariance} argument for results presented in terms of mean and standardized mean differences, which related to the \texttt{covar.smd} function. The alternative \texttt{covariance == "indep"} can be specified for assuming independence of the log relative risks or differences in means. This is particularly useful when the information for reconstructing the covariances is not available (see additional (useful) code section on the referenced site for examples).

\noindent The implementation of the one-stage approach and related functions is discussed in more details in the methods for \citetalias{crippa2018one}. 
The updated \pkg{dosresmeta} package implements also functions to facilitate specific aspects of a dose--response meta-analysis. These includes the assessment of goodness-of-fit discussed in \citetalias{discacciati2015goodness}, tests for fixed- and random-effects coefficients, conditional and marginal predictions, and the use of fractional polynomials.

Based on the last version of the \pkg{dosresmeta} package, an interactive interface is also available at \url{http://alessiocrippa.com/shiny/dosresmeta}. The web-app can be useful for introducing to the concepts of dose--response meta-analysis those researchers who are not familiar with the \textsf{R} software.

\subsection{Description of the package}

The \pkg{dosresmeta} package can be downloaded from CRAN by typing directly in \textsf{R} 
<<download, eval=FALSE, echo=TRUE>>=
install.packages("dosresmeta")
@
The version under development is instead available from GitHub
<<download_git, eval=FALSE, echo=TRUE>>=
install.packages("devtools")
devtools::install_github("alecri/dosresmeta")
@

\noindent The package consists of a main function \texttt{dosresmeta} with the following arguments
<<usage, echo = TRUE, R.options=list(width = 80)>>=
str(dosresmeta)
@

The dose--response model is specified in the \texttt{formula} argument in a symbolic representation. For example, if logrr and dose are the variable name for the log relative risk and assigned doses, a linear trend is specified as \texttt{logrr $\sim$ dose} while a quadratic curve as \texttt{logrr $\sim$ dose + I(dose)\^{}2}. The variable are defined in a data.frame whose name in specified in the \texttt{data} argument. By default \texttt{intercept = FALSE} does not include the intercept term in the covariance matrix, which is constructed in terms of contrasted unless \texttt{center = FALSE}. The \texttt{id} argument specifies the name for the study id variable (can be omitted for single study analysis). 
The standard errors for the log relative risks is specified in the \texttt{se} argument, or alternatively, either the variances (\texttt{v}) or the lower (\texttt{lb}) and upper bounds (\texttt{ub}) of the relative risks need to be specified. The additional information about the study-design (\texttt{type}), the number of cases (\texttt{cases}), and participants or amount of person-time (\texttt{n}) is used for reconstructed the covariance of the log relative risk (or mean differences) using the method specified in the \texttt{covariance} argument (default is the Greenland and Longneckerâ€™s method). In alternatively, a list of covariance matrices can be passed to the \texttt{Slist} argument when \texttt{covariance = "user"}.
As defaults, a two-stage procedure with REML estimation methods (\texttt{method}) are selected. Alternatives are a one-stage procedure (\texttt{proc = "stage"}) and either ML estimators \texttt{method = "ml"} or a fixed-effect analysis \texttt{method = "fixed"}. Residual heterogeneity can be modeled in a meta-regression analysis specified in the \texttt{mods} argument. For example, a different curve depending on the study design can be specified with \texttt{mods = $\sim$ type}. Finally, a list of parameters can be passed to the \texttt{control} argument to control the fitting process.

The \texttt{dosresmeta} function returns an object of class ``\texttt{dosresmeta}'' with the information from the dose--response meta-analytic model. The \texttt{print} and \texttt{summary} methods display and produce a summary of the content of a \texttt{dosresmeta} object. The \texttt{predict} method facilitates the presentation of the results of a dose--response meta-analysis

<<pred, echo = TRUE, R.options=list(width = 80)>>=
str(dosresmeta:::predict.dosresmeta)
@

\noindent where object contains the results of the \texttt{dosresmeta} function. A new data.frame with the desired doses can be passed to the \texttt{newdata} argument for obtaining the corresponding predicted log relative risks. If not provided, the predictions will be calculated for the assigned dose values across the studies. The \texttt{expo} argument can be set to \texttt{TRUE} to predict log relative risk and confidence intervals (unless \texttt{ci.incl = FALSE}) on the exponential scale. The referent value can be specified with the \texttt{xref} argument, or better, specifying the line of the newdata which serves as referent (\texttt{xref\_pos} argument). For non-linear models the a vector need to be provided in \texttt{xref\_vec} instead of \texttt{xref}. The \texttt{delta} argument is useful to predict the linear increase in the outcome for a delta increase in the exposure, and is thus only appropriate in a linear trend analysis. In the updated version of the \pkg{dosresmeta} package, a \texttt{blup} method has also been implemented to predict the study-specific random-effects and hence the conditional curves.

Additional functions can be listed

<<fun, echo = TRUE>>=
ls("package:dosresmeta")
@

\noindent Use \texttt{ls(getNamespace("dosresmeta"), all.names=TRUE)} for a complete list including hidden auxiliary functions.


\section{Goodness-of-fit}\label{sec:gof}

The aim of \citetalias{discacciati2015goodness} was to address how to evaluate the goodness-of-fit in dose--response meta-analysis. The issue is particularly relevant in a dose--response analysis where the predicted curve should be a reasonably good summary of the modelled log relative risks. However, different features of aggregated dose--response data can complicate this comparison. The predicted curve is presented using a referent, $x_\mathrm{ref}$, which may differ from the study-specific reference values. Thus the predicted and observed log relative risks can no longer be directly compared because their baseline group comparison is not the same. Even in the case where the reference values are all the same and equal to $x_\mathrm{ref}$, the covariance among the study-specific RRs and the heterogeneity across the studies add further difficulties in evaluating if the chosen model provides a good summary of the observed data. Therefore, the proposed tools for assessing the goodness-of-fit are presented in a fixed-effect analysis where meta-regression models as in~\ref{eq:rmmra2} are typically employed to explain the observed heterogeneity. We consider relevant measures, tests, and graphical tools that take into account the correlation of the observed data.

\subsection{Deviance} 

The first natural measure of goodness-of-fit is a comparison between the predicted and observed data points, that is the non-referent log relative risks. This can be done by analyzing the residual term errors, which is defined by the difference between the observed log RRs $\mathbf{y}_i$ and the marginal prediction
\begin{equation}
\boldsymbol{\hat e_i} = \mathbf{y}_i - \mathbf{X}_i \mathbf{Z}_i \boldsymbol{\hat \beta}
\label{eq:residual}
\end{equation}\noindent A summary for the error terms is the deviance
\begin{equation}
D = \sum_{i=1}^I \left(\mathbf{y}_i - \mathbf{X}_i \mathbf{Z}_i \boldsymbol{\hat \beta} \right)^\top \mathbf{S}_i^{-1} \left(\mathbf{y}_i - \mathbf{X}_i \mathbf{Z}_i \boldsymbol{\hat \beta} \right) = \sum_{i=1}^I \boldsymbol{\hat e_i}^\top \mathbf{S}_i^{-1} \boldsymbol{\hat e_i}
\label{eq:deviance}
\end{equation}

\noindent The deviance $D$ measures the total squared deviation between observed and predicted data taking into account the covariance matrices $\mathbf{S}_i$ of the error terms. It is usually referred to as generalized residual sum of squares (GRSS) \citep{draper2014applied}. Decreasing values of $D$ indicate a better agreement between reported and fitted log RRs, with 0 being the lower bound that corresponds to perfect agreement (saturated model).

\noindent The $D$~statistic can be used as a test for model specification. Under the null hypothesis that the model is correctly specified, $D$ follows a $\chi^2$ distribution with $df = n - pm$. This is equivalent to test if the residual variance, corrected for the correlation of the error terms, is larger than expected assuming that the dose--response model is correct. A small $p$~value can be interpreted as evidence that the fitted model fails in accounting the observed variation in the log relative risks. As for the $Q$~test, the deviance has no upper bound has is thus difficult to interpret the absolute value $D$.

\subsection{Coefficient of determination}

To complement the $D$~statistic (and the corresponding test), the coefficient of determination, $R^2$, can be used as a descriptive measure of goodness-of-fit \citep{hagquist1998goodness, kvaalseth1985cautionary}. The $R^2$ is the complement to the unit of the ratio between the $\textrm{GRSS}$ and the generalized sum of squares $\textrm{GTSS} = \sum_{i=1}^I\mathbf{y}_i^\top \mathbf{S}_i^{-1} \mathbf{y}_i$. Because the dose--response models do not have the intercept term, the $R^2$ can be defined as in \cite{buse1973goodness, theil1958economic}
\begin{equation}
R^2 = 1 - \frac{\textrm{GRSS}}{\textrm{GTSS}} = 1 - \frac{\sum_{i=1}^I \left(\mathbf{y}_i - \mathbf{X}_i \mathbf{Z}_i \boldsymbol{\hat \beta} \right)^\top \mathbf{S}_i^{-1} \left(\mathbf{y}_i - \mathbf{X}_i \mathbf{Z}_i \boldsymbol{\hat \beta} \right)}{\sum_{i=1}^I \mathbf{y}_i^\top \mathbf{S}_i^{-1} \mathbf{y}_i}
\label{eq:R2}
\end{equation}
\noindent The $R^2$ is a dimensionless number that is bounded between 0 and 1, and can be generally interpreted as the proportion of the generalized total sum of squares explained by the dose--response model and study-level covariates. The lower bound 0 corresponds to the case where all the $\beta$ coefficients are equal to 0 and therefore the model is not able to explain the variability in the observed log relative risks. Contrary, the upper bound 1 indicates a perfect agreement between reported and fitted data. 

By construction the $R^2$ can not decrease as the number of regression coefficients increases. A penalized, or adjusted, version that takes into account this behavior can be defined
\begin{equation}
R^2_{\textrm{adj}} = 1 - \frac{n}{n-pm} \left(1 - R^2 \right)
\label{eq:R2adj}
\end{equation}

Possibly, a low $R^2$ may indicate that more flexible transformations of the exposure are needed, or that there is considerable residual variability that might be explained by study-level covariates.

\subsection{Visual tools}

<<>>=
# code: breast_SEER_visual agreement.R
breast_1501$age_cat <- cut(breast_1501$age, c(20, 35, 60, 70, 97),
                           include.lowest = T)
pos <- 1
cat_1501 <- glm(Y ~ relevel(age_cat, 1) + histology + maritalStatus + race +
                  tumor_size + radiation + grade + ER + PR + node_pos, 
                data = breast_1501, family = "poisson", offset = log(surv_time))
# creatig aggregated data
cat_res <- ci.exp(cat_1501)[1:4,] %>% 
  data.frame() %>%
  mutate(
    ci = paste0("(", round(X2.5., 2), ", ", round(X97.5., 2), ")"),
    logrr = coef(cat_1501)[1:4],
    se = diag(vcov(cat_1501))[1:4]^.5,
    refpos = c(pos, setdiff(1:4, pos))
  ) %>%
  arrange(refpos)
cat_res[pos, ] <- c(1, 1, 1, NA, 0, 0, pos)
tab_1501 <-breast_1501 %>%
  group_by(age_cat) %>%
  summarise(dose = mean(age),
            cases = sum(Y),
            PT = sum(surv_time)) %>%
  cbind(cat_res)
lin_ad <- dosresmeta(logrr ~ dose, type = "ir", se = se, cases = cases, n = PT,
                     data = tab_1501)
delta_lin <- predict(lin_ad, delta = 1, expo = T)
# changing reference category using Hamling's method
tab_1501_2 <- dosresmeta:::change_ref(y = logrr, v = se^2, cases = cases, n = PT, 
                                      type = "ir",  data = tab_1501, ref = 2, expo = T) %>%
  mutate(logrr = log(rr.2), 
         se = (log(ub_rr.2) - log(lb_rr.2))/(2*1.96),
         dose = tab_1501$dose)
# linear model on the alternative tabdata
lin_ad_2 <- dosresmeta(logrr ~ dose, type = "ir", se = se, cases = A.2, n = N.2,
                     data = tab_1501_2)
@

The visual assessment of the goodness-of-fit may reveal specific patterns in the data that might otherwise go undetected by only looking at summary measures such as the deviance and the coefficient of variation \citep{kvaalseth1985cautionary}. The graphical comparison can sometimes be delicate because different factors may affect such analysis. The aggregated dose--response data are presented using one group as comparison. This feature has two important consequences when deducting an overall trend from the reported (log) relative risks. The former is that different parameterizations, or models, can be graphically compared only if the predicted risk for the reference category is similar. The latter, instead, involves the correlation of the modelled data points which makes even harder to evaluate if a specific model fits the reported data. To illustrate both the problems we consider IPD from one of the registers involved in the Surveillance, Epidemiology, and End Results (SEER) Program (\url{https://seer.cancer.gov}), and focus on the association between age at diagnosis and breast cancer mortality. 

<<breast_ad, results='asis'>>=
# code: breast_SEER_visual agreement.R
tab_1501 %>%
  select(-`X2.5.`, -`X97.5.`, -refpos) %>%
  `colnames<-`(c("Age category", "Mean age", "Cases",
                 "Person-years", "IRR", "95% CI", "log IRR", "SE")) %>%
  xtable(digits = c(2,0,1,0,1,2,2,2,2), align = "ccccccccc", label = "tab:breast_ad",
         caption = "Aggregated dose-response data on the adjusted association between age and breast cancer mortality based on one registry from the SEER program using the first age category as referent.
         ") %>%
  print(include.rownames = FALSE, caption.placement = "top")
@

Using 35, 60, 70 year as cut points, we modelled age using 5 categories in a Poisson model adjusting for potential confounders and produced aggregated dose--response results in table~\ref{tab:breast_ad}, using the first category as referent. Using the methodology presented in section~\ref{sec:1st_stage}, we estimated a linear trend a graphically compared the predicted trend and the tabular data (figure~\ref{fig:visual_problem}). While the reported log RRs suggest an inverse association between age and breast cancer mortality, the estimated linear trend indicates opposite conclusion (a \Sexpr{round(100*(delta_lin$pred-1), 2)}\% increase in mortality for every 5-year increase of age at diagnosis). The linear trend does not seem to properly fit the data since the fitted lined doesn't event pass through the reported log RRs. The problem is that there are few cases in the reference age category and so the log RRs are more unstable. By changing the group comparison to the second age category, this issue is partially solved. To address the further issue of the covariance, we proposed graphical tools based on the analysis of the decorrelated residuals.

<<visual_problem, fig.cap = 'Comparison between observed and fitted data using changing the comparison group from the first age category (left panel) to the second one (right panel) based on the aggregated data on the association between age and breast cancer mortality presented in table~\\ref{tab:breast_ad}', fig.height=4>>=
# code: breast_SEER_visual agreement.R
gridExtra::grid.arrange(
  ggplot(tab_1501, aes(x = dose, y = exp.Est..)) + 
    geom_point() +
    geom_errorbar(aes(ymin = X2.5., ymax = X97.5.)) +
    geom_line(aes(y = predict(lin_ad, xref_pos = pos, expo = T)$pred)) +
    scale_y_continuous(trans = "log", breaks = c(.5, .6, .7, .8, .9, 1, 1.1)) +
    labs(y = "Relative risk", x = "Age (years)"),
  ggplot(tab_1501_2, aes(x = dose, y = rr.2)) + 
    geom_point() +
    geom_errorbar(aes(ymin = lb_rr.2, ymax = ub_rr.2)) +
    geom_line(aes(y = predict(lin_ad_2, xref_pos = 2, expo = T)$pred)) +
    scale_y_continuous(trans = "log", breaks = c(1, 1.1, 1.25, 1.5, 1.75, 2)) +
    labs(y = "Relative risk", x = "Age (years)"),
  nrow = 1, ncol = 2
)
@

The residuals can be decorrelated using the Cholesky factorization of the covariance matrices $\mathbf{S}_i = \mathbf{C}_i\mathbf{C}_i^\top$, with $\mathbf{C}_i$ being a lower triangular matrix $J_i \times J_i$. The decorrelated residuals $\boldsymbol{\hat e_i}^*$ are then calculated as
\begin{equation}
\boldsymbol{\hat e_i}^* = \mathbf{C}_i^{-1} \left(\mathbf{y}_i - \mathbf{X}_i \mathbf{Z}_i \boldsymbol{\hat \beta} \right) = \mathbf{C}_i^{-1}\boldsymbol{\hat e_i}
\label{eq:decor_res}
\end{equation}

\noindent and plotted against the exposure. Such a graphical analysis is the equivalent of a residual vs. predictors/predicted outcome plot after a model estimated through ordinary least squares. Since the variables in the plot are transformed, the actual value of the decorellated residuals is not directly interpretable. However, it is still possible to detect specific patterns for the residuals over the exposure range. In such a case, the plot can indicate lack of fit of the fitted model for select exposure values. Overlaying a locally weighted scatterplot smoothing (LOWESS) may help to visualize possible patterns, while a different shape or color for the residuals can distinguish them according to study-level covariates in case of meta-regression models.



\section{A new measure of heterogeneity}

One of the possible reasons for large values of $D$ or similarly small values of $R^2$ is presence of heterogeneity in the dose--response associations. The measures of heterogeneity presented in section~\ref{sec:measures_het}, namely $\hat R_I$ and $I^2$ were derived based on the assumption of homogeneity for the error variance terms $v_i$, which is unlikely to be met in applications. To illustrate this point, let us consider the two hypothetical distributions for the within-study error terms in table~\ref{tab:hyp_vi}. The distribution of $v_i$ in the first example (analysis A) is much more homogeneous compared to the second scenario (analysis B). The coefficient of variation for the $v_i$ in the second example is 20 times higher than the corresponding number in the first scenario. While it seems reasonable to assume homogeneity of the $v_i$ for the analysis A, in the second case this hypothesis is not appropriate. Nonetheless both $\hat R_I$ and $I^2$ would summarize the two distributions with a single common number. 

<<hyp_vi, results='asis'>>=
# code: hypothetical_vi.R
hyp_vi %>%
  `colnames<-`(c("Analysis", "$v_1, \\dots, v_5$", "$CV_{v_i}$",
                 "$s_1^2$", "$s_2^2$")) %>%
  xtable(digits = c(0, 0, 0, 2, 1, 1), align = "cccccc", label = "tab:hyp_vi",
         caption = "Hypothetical distributions of within-study errors 
in two meta-analyses of 5 studies.") %>%
  print(include.rownames = FALSE, caption.placement = "top",
        sanitize.text.function=identity)
@

\subsection{Definition and properties}

The available measures relate the between-study heterogeneity to the overall variability, whose definition also varies across a study. A different prospective consists of measuring the impact of heterogeneity in determining the variance of the combined effect in a random-effects analysis. This quantity depends on the $\tau^2$ and on the variance of the combined $\hat \beta$, quantities that don't require the assumption of homogeneity for the within-study error terms.

\noindent To determine how $\tau^2$ contributes to give $\widehat{\Var} \left(\hat \beta \right)$, we consider the hypothetical case where all the estimates $\hat \beta_i$ are reported with no error, i.e. $v_i = 0 \; \forall i = 1, \dots, I$. The weights used in the meta-analytic model depends only on $\tau^2$, and following equation~\ref{eq:avgvarbeta} the variance of the combined effect is $\widehat{\Var} \left(\hat \beta \right) = \left(\sum_{i = 1}^I \hat \tau^2 \right)^{-1} = \hat \tau^2/I$.
In the more realistic case where $v_i > 0$, the variance of $\hat \beta$ will increase to incorporate the uncertainty in the reported estimates. The contribution of the heterogeneity is still defined by $\hat \tau^2/I$. The new measure of heterogeneity, $R_b$, can be written as
\begin{equation}
\hat R_b = \frac{\hat \tau^2}{I \widehat{\Var} \left(\hat \beta \right)} = \frac{\hat \tau^2}{I/\left( \sum_{i = 1}^I \frac{1}{v_i + \hat \tau^2} \right)} = \frac{1}{I}\sum_{i = 1}^I \frac{\hat \tau^2}{\hat \tau^2 + v_i}
\label{eq:Rb}
\end{equation}

\noindent The $\hat R_b$ is a dimensionless number that can be expressed as a percentage, ranging from 0\% (corresponding to $\hat \tau^2 = 0$, i.e. no observed heterogeneity) to 100\%, for the hypothetical case where all the effects are estimated with no error. The proposed measure is defined as a function of the estimated heterogeneity ($\tau^2$), the number of studies (I), and the within-study error terms ($v_i$). It satisfies the criteria required for a measure of heterogeneity \citep{higgins2002quantifying}: it is a non-decreasing function of $\hat \tau^2$, it is invariant to scale transformation of the estimates, and is not intrinsically affected by the number of studies included in the analysis. Similarly to $\hat R_I$ and $I^2$, the proposed measure is a function on the within-error terms $v_i$ and so it tends to 1 in case of meta-analysis of very precise estimates, even for relative small values of $\hat \tau^2$. As already mentioned in section~\ref{sec:measures_het}, the use of the between-studies coefficient of variation can complement these measures \citep{takkouche1999evaluation}.

\noindent The right hand of equation~\ref{eq:Rb} expresses $\hat R_b$ as an average of the ratios of the $\hat \tau^2$ to the study-specific overall variance $v_i + \hat \tau^2$. It is easy to derive that $\hat R_b$ coincides with the definition of $\hat R_I$ and $I^2$ in case of homogeneity of the $v_i$. When the within-errors vary across study, the difference between $\hat R_b$ and $I^2$ will depend on the actual values of $v_i$, while it can be proven that $\hat R_b \le \hat R_I$.

An estimate of the between-study heterogeneity is required for the computation of $\hat R_b$ as well for the alternative measures $\hat R_I$ and $I^2$. The moment-based estimator presented in equation~\ref{eq:tau2DL} is a standard choice in many applied meta-analyses and has the advantage of having a closed formulation. In addition, the estimator is asymptotically consistent \citep{jackson2010extending}. Using this estimation method, $\hat R_b$ can be expressed as a function of the $Q$~statistic
\begin{equation}
\hat R_b = \frac{1}{I} \sum_{i = 1}^I \frac{Q - (I-1)}{Q + a_i - (I - 1)} 
\label{eq:RbQ}
\end{equation}
\noindent with $a_i = v_i \left(\sum_{i = 1}^I w_i - \sum_{i = 1}^Iw_i^2/\sum_{i = 1}^I w_i \right)$. The asymptotic variance for $\hat R_b$ can be derived by using the delta method on the relation~\ref{eq:RbQ}
\begin{equation}
\widehat{\Var} \left(\hat R_b \right) \approx \left(  \frac{1}{I} \sum_{i = 1}^I \frac{a_i}{(Q + a_i - (I-1))^2} \right)^2 \Var(Q)
\label{eq:var_Rb}
\end{equation}

\noindent The formula for $\Var(Q) = 2(I-1) + 4\left(S_1 - \frac{S_2}{S_1}\right)\tau^2 + 2\left(S_2 - 2\frac{S_3}{S_1} + \frac{S_2^2}{S_1^2} \right)$, with $S_r = \sum_{i = 1}^I w_i^r$, was first presented by \cite{ biggerstaff1997incorporating}.

\noindent When the number of studies is large, $\hat R_b$ is asymptotically distributed and thus Wald-type confidence interval can be constructed $\hat R_b \pm z_{1-\alpha/2} \sqrt{ \widehat{\Var} \left(\hat R_b \right)}$.



\section{A point-wise approach}

<<>>=
# code: motivating_pointwise.R
data("milk_mort")
id_milk <- c(14, 11, 9, 3) 
milk_sub <- filter(milk_mort, id %in% id_milk)
q_milk <- quantile(milk_sub$dose, c(.1, .5, .9))
max_dose <- tapply(milk_sub$dose, milk_sub$id, max)
fps <- fpgrid()
shift <- 5
scale <- 10
modi_milk <- lapply(split(milk_sub, milk_sub$id), function(d){
  lapply(split(fps, 1:nrow(fps)), function(p){
    dosresmeta(logrr ~ fracpol(dose, p = p, shift, scale),
               se = se, type = type, cases = cases, n = n, data = d)
  })
})
AIC_i <- lapply(modi_milk, function(m) sapply(m, AIC))
best_i <- sapply(AIC_i, which.min)
fpbest <- fps[best_i, ]
modi_milk_sel <- Map(function(m, i) m[[i]], modi_milk, best_i)
p_milk <- Map(function(d, m, p){
  newdata <- data.frame(dose = seq(min(d$dose), max(d$dose), length.out = 100)) %>%
    mutate(pred = predict(m, ., expo = T)$pred)
  ggplot(d, aes(dose, rr)) +
    geom_errorbar(aes(ymin = lb, ymax = ub)) +
    scale_y_continuous(trans = "log", breaks = c(.5, .6, .7, .85, 1, 1.25, 1.5)) +
    labs(y = "Relative risk", x = "Milk consumption (ml/day)", 
         title = paste0("Study ID ", d$id[1], ", p = (", paste0(p, collapse = ", "), ")")) +
    geom_line(data = newdata, aes(x = dose, y = pred))
}, d = split(milk_sub, milk_sub$id), m = modi_milk_sel, p = split(fpbest, 1:nrow(fpbest)))
@

Measures of heterogeneity are frequently employed in applied works and in applications of meta-regression models. In a dose--response meta-analysis, however, there are two aspects of heterogeneity that can not be captured using standard methods. More specifically, in a two-stage analysis the same functional transformations $g_1, \dots, g_p$ need to be defined for all the studies so that the regression coefficients can be properly combined by meta-analysis.
This may have important consequences in case the chosen dose--response model adequately fits only a subset of the analyzed studies. To illustrate this aspect, we consider a subset of 4 studies on the association between milk consumption (ml/day) and all-cause mortality \citep{larsson2015milk}. We modelled the individual curves using FP2 and selected in each study the combination of power terms which maximized the log likelihood (or equivalently with the minimum AIC). The chosen power terms in the individual analyses differ although the predicted curves describe a similar association figure~\ref{fig:milk_sub}. Forcing a unique set of power terms may decrease the fit of some of the study-specific analyses and thus produce more unstable estimates for the dose--response parameters.

\noindent An other difficulty may be encountered in uniformly defining the $g$ transformation across the studies. For instance, we might decide to model the previous association between milk consumption and mortality using RCS. A percentile approach is commonly adopted for choosing where to place the $\mathbf{k}$ in equation~\ref{eq:rcs}. The first and third knots at located at the extremes, generally at the 10-th and 90-th percentiles of the exposure distribution, while the median exposure value is chosen for the remaining knot.
If the exposure distributions largely vary (especially in terms of range definition), as it is in this case, it may not be possible to equally locate the knots in all the studies. Indeed, in our example only one study considered dose levels higher than the upper knot (\Sexpr{q_milk[3]} ml/day). As a consequence, the second spline transformation for the other studies will is equal 0 and the model is not estimable (the design matrix is not invertible). 

\noindent A second related problem directly affects the prediction of the pooled log relative risks. The maximum dose levels varies largely across studies, with values \Sexpr{paste(max_dose, collapse = ",")} ml/day. 
The predictions from the second stage analysis, however, are obtained using the combined $\boldsymbol{\hat \beta}$, which disregard information about the exposure ranges. All the studies contribute in predicting the log relative risks, even if some of them only reported results for low exposure values. In such a way, the combined curve may severely affected by these extrapolations.

A pointwise approach for meta-analysis of aggregated dose--response data may properly address the described issues.

<<milk_sub, fig.cap="Dose-response associations between milk consumption (ml/day) and all-cause mortality in 4 studies. The curves are modelled using fractional polynomials with the sets of power terms $p$ (reported in the title) chosen by maximizing the study-specific likelihoods. The results are presented on the log scale using the observed reference values as comparators.", fig.height=7>>=
# code: motivating_pointwise.R
marrangeGrob(grobs = p_milk, ncol = 2, nrow = 2, top = NULL)
@

A pointwise approach was first presented by \cite{sauerbrei2011new} for meta-analysis of continuous covariates based on IPD. The strategy consists of separately estimating the study-specific curves and, based on them, calculating the predicted log relative risks for selected exposure values. The combined curve is obtained by pooling the predicted relative risks instead of calculating them from the combined regression coefficients. The described methodology has the advantage of fitting potential diverse curves across the studies, and limiting the study-specific predicted log relative risks to the observed exposure range.   

\subsection{Estimation and prediction of study-specific curves}

The first step of a pointwise approach is similar to the methodology presented in section~\ref{sec:1st_stage} with the difference that the $g$ transformations in the design matrices~\ref{eq:des.matrix} are subscripted by the study index $i$, to highlight that they may differ across the studies, also in terms of number ($p_i$) 
\begin{equation}
 \mathbf{X}_i=\left[
\begin{array}{ccc}
g_{i1}(x_{i1}) - gi_{1}(x_{i0}) & \hdots & g_{ip_i}(x_{ip}) - g_{ip_i}(x_{i0}) \\
\vdots &  & \vdots \\
g_{i1}(x_{iJ_i}) -  gi_{1}(x_{i0}) & \hdots & g_{ip_i}(x_{iJ_i}) -  g_{ip_i}(x_{i0}) \\
\end{array}
\right] 
\label{eq:des.matrix_pwa}
\end{equation}
\noindent For example, different power terms for FP2 can be chosen or, for a RCS analysis, the knots can be located separately in each study. Potentially, a mixed of curves could be also estimated across the study in order to improve the fit of the individual dose--response analyses. The regression coefficients are then be estimated using generalized least squares estimators presented in equation~\ref{eq:gls}.

Once the curves have been estimated, the results of the first step analysis are presented in terms of predicted log relative risks of a set of $v_i$ exposure values $\mathbf{x_{v_i}}$ using a suitable value $x_\mathrm{ref}$ as comparator. The $i$ indexed is used to highlight that the chosen dose values may differ across the studies. In particular, the predictions in each study can be limited to the observed exposure range $\max \left( \mathbf{x_{v_i}} \right) \le \max{\mathbf{x_i}}$.
\begin{align}
\hat {\boldsymbol y}_i &= \mathbf{X}_{v_i} \boldsymbol{\hat \beta_i}
\label{eq:pred_pwa} \\
\hat{\boldsymbol{v}}_i &= \mathrm{diag}\left( \mathbf{X}_{v_i} \widehat{\Var} \left( \boldsymbol{\hat \beta_i} \right) \mathbf{X}_{v_i}^\top \right)
\label{eq:predv_pwa}
\end{align}
\noindent with formulas similar to those presented in equation~\ref{eq:pred} and ~\ref{eq:varpred}, with the notable difference that the predictions are based on the study-specific $\boldsymbol{\hat \beta_i}$ rather than the mean $\boldsymbol{\hat \beta}$ coefficients.

\subsection{Averaging of dose--response prediction}

In a pointwise strategy the combined dose--response curve is derived by pooling the study-specific predicted log relative risks derived in equation~\ref{eq:pred_pwa}. The second step analysis consists of $v = \max(v_i)$ univariate meta-analyses where the effect sizes are the elements in $\hat {\boldsymbol y}_i$ with the within-error variances $\hat{\boldsymbol{v}}_i$.
The combined predicted relative risks are estimated using the weighted average presented in equation~\ref{eq:avgbeta}.

As a final result, the combined dose--response curve is graphically presented as a smooth function of the combined predicted relative risks for the chosen $v$ dose levels. In addition, all the results of the univariate meta-analyses can be pointwisely presented, such as estimates of the heterogeneity $\tau^2$ and related measures, $R_b$, $I^2$, and $R_i$, the $Q$~statistic, and the study-specific weights, with the potential of a much richer set of results.


\section{A one-stage model}

The study-specific dose--response analysis in a standard two-stage or alternative pointwise approach suffer from the limited number of data points. Most of the individual studies present results for 2 to 4 non-referent exposure categories, but cases where dichotomization of the exposure occurred are not rare \citep{turner2010categorisation}. In the latter case, only dose--response models parameterized by $p = 1$ coefficient can be estimated (e.g. linear trend). Indeed, a standard requirement for meta-analysis of non-linear curves is that the studies provide at least two non-referent relative risks.

The extension of the one-stage approach to a random-effects meta-analysis may overcome the constrain from the limited number of individual data points. A one-stage approach is conceptually easier since the entire analysis can be formulated in a single statistical model. Flexible curves characterized by multiple parameters ($p > 3$) can be easily accommodated, so that more elaborate research questions can be answered, without loosing the information from those studies usually excluded in a two-stage analysis.

\subsection{Model definition}

A one-stage dose--response meta-analysis can be written in the form of a linear mixed-effects model
\begin{equation}
\mathbf{y}_{i} = \mathbf{X}_{i} \boldsymbol{\beta} + \mathbf{Z}_{i}  \mathbf{b}_i + \boldsymbol{\varepsilon}_{i}
\label{eq:onestage}
\end{equation}
\noindent where the terms $\mathbf{y}_{i}$, $\mathbf{X}_{i}$, and $\boldsymbol{\varepsilon}_{i}$ are defined exactly as those presented in the first step of a two-stage analysis (equation~\ref{eq:drmodel}). The quantities $\boldsymbol{\beta}$ and $\mathbf{b}_i$, instead, are the population average parameter and unobserved random-effects as defined in second step (equation~\ref{eq:rmma}). The additional $\mathbf{Z}_{i}$ is the $n_i \times p$ design matrix for the random-effects and coincides with the definition of $\mathbf{X}_{i}$.

\noindent Placing the multivariate distribution for the random-effects terms, the marginal model for a one stage analysis is
\begin{equation}
\mathbf{y}_{i} \sim \mathcal{N} \left( \mathbf{X}_{i} \boldsymbol{\beta},  \mathbf{Z}_{i} \boldsymbol{\Psi} \mathbf{Z}_{i}^\top  + \mathbf{S}_i \right)
\label{eq:marginal_os}
\end{equation}
\noindent Similarly, the conditional model is defined as
\begin{equation}
\mathbf{y}_{i} \mid \boldsymbol{b}_i \sim \mathcal{N} \left( \mathbf{X}_{i} \boldsymbol{\beta} + \mathbf{Z}_{i} \boldsymbol{b}_i,  \mathbf{S}_i \right)
\label{eq:conditional_os}
\end{equation}

\noindent Note that the conditional and marginal models are now defined for the log relative risks rather than the dose--response coefficients. In particular, the definition of the marginal variance $\boldsymbol{\Sigma}_i  = \mathbf{Z}_{i} \boldsymbol{\Psi} \mathbf{Z}_{i}^\top  + \mathbf{S}_i$ is quite different. It depends not only on the within and between components but also on the corresponding dose value $x_{ij}$ (or equivalently $z_{ij}$) associated with $y_{ij}$.

Meta-regression models can be estimated by including in $\mathbf{X}_{i}$ the interaction terms between the $p$ transformations of the exposure variable and study-level covariates, while leaving unchanged the definition of the $\mathbf{Z}_{i}$ matrix for the random-effects. Assuming a quadratic curve and a binary study-level covariate $u_i$, the design matrices for the fixed- and random-effects can be written as
\begin{equation*}
\mathbf{X}_i =
	\begin{bmatrix}
		x_{i1} - x_{i0}  & x_{i1}^2 - x_{i0}^2 & \left(x_{i1} - x_{i0}\right) u_i &  \left( x_{i1}^2 - x_{i0}^2\right) u_i \\
		\vdots & \vdots & \vdots & \vdots \\
		x_{iJ_i} - x_{i0}  & x_{iJ_i}^2 - x_{i0}^2 & \left(x_{iJ_i} - x_{i0}\right) u_i  & \left(x_{iJ_i}^2 - x_{i0}^2\right) u_i \\
	\end{bmatrix}
\end{equation*} 

\begin{equation*}
\mathbf{Z}_i =
	\begin{bmatrix}
		x_{i1} - x_{i0}  & x_{i1}^2 - x_{i0}^2 \\
		\vdots & \vdots \\
		x_{iJ_i} - x_{i0}  & x_{iJ_i}^2 - x_{i0}^2 \\
	\end{bmatrix}
\end{equation*} 

\subsection{Estimation and hypothesis testing}

The parameters to be estimated are the $m\times p$ fixed effects and the $p \times (p+1)/2$ elements of the between-study variance matrix. We consider likelihood-based estimators that maximize either the log-likelihood of model~\ref{eq:conditional_os}
\begin{equation}
\ell \left( \boldsymbol{\beta}, \boldsymbol{\xi} \right) = 
 -\frac{1}{2} n \log(2\pi)  -\frac{1}{2} \sum_{i=1}^I \log | \boldsymbol{\Sigma}_i \left( \boldsymbol{\xi} \right) |  -\frac{1}{2}\sum_{i=1}^I \left[ \left( \mathbf{y}_i -  \mathbf{X}_i \boldsymbol{\beta} \right)^\top \left( \boldsymbol{\Sigma}_i \left( \boldsymbol{\xi} \right) \right)^{-1} \left( \mathbf{y}_i -  \mathbf{X}_i \boldsymbol{\beta} \right) \right]
\label{eq:logLik_os}
\end{equation}
\noindent or the corresponding restricted version
\begin{equation}
\begin{split}
\ell_R \left( \boldsymbol{\xi} \right) = & 
 -\frac{1}{2} (n - p) \log(2\pi)  - \frac{1}{2} \sum_{i=1}^I \log | \boldsymbol{\Sigma}_i \left( \boldsymbol{\xi} \right) |  - \frac{1}{2} \log \left| \sum_{i=1}^I \mathbf{X}_i^T \left( \boldsymbol{\Sigma}_i \left( \boldsymbol{\xi} \right) \right)^{-1}  \mathbf{X}_i  \right| + \\
&-\frac{1}{2}\sum_{i=1}^I \left[ \left( \mathbf{y}_i -  \mathbf{X}_i \boldsymbol{\hat \beta} \right)^\top \left( \boldsymbol{\Sigma}_i \left( \boldsymbol{\xi} \right) \right)^{-1} \left( \mathbf{y}_i -  \mathbf{X}_i \boldsymbol{\hat \beta} \right) \right]
\end{split}
\label{eq:logLikR_os}
\end{equation}

As in case of multivariate meta-analysis, likelihood estimators requires iterative algorithms in optimizing the functions~\ref{eq:logLik_os} and ~\ref{eq:logLikR_os}. 
In particular, the Nelder-Mead method can be employed to find the maximum for the parameters in the multidimensional domain. For ease of computation, both likelihoods are expressed as function of only the $\boldsymbol{\xi}$ parameters, which corresponds to the elements of the lower triangular Cholesky decomposition of $\boldsymbol{\Psi}$. The algorithms start with an initial guess for $\boldsymbol{\Psi}$, obtain an estimate for $\boldsymbol{\beta}$ using GLS estimators and maximize the objective function in terms of $\boldsymbol{\xi}$. The steps are iterated until convergence.

Test of hypothesis and confidence intervals are based on the established theory for mixed models. Inference on the fixed-effects coefficients is conducted in a similar way as presented in section~\ref{sec:2nd_stage}, using the asymptotic normal distribution for the estimator of $\boldsymbol{\beta}$. Tests for the variance components, instead, generally require a mixture of $\chi^2$ because the coefficients to be tested can only be positive. When $p \ge 2$, however, the distribution of the test statistic is difficult to implement, so that alternative measures can be instead applied. Following the idea behind the definition of the Intraclass Correlation Coefficient (ICC), the marginal variance in~\ref{eq:marginal_os} can also be decomposed in the within-study and between-studies components. The dose--response model~\ref{eq:onestage} is a mixed model with random-effects for the slope terms and with no intercept. Thus, the between-studies variance is a quadratic function of the assigned dose values. For this setting \cite{goldstein2002partitioning} defined the Variance Partition Coefficient (VPC) as the ratio of the between-studies component by the total residual variability
\begin{equation}
\textrm{VPC}_{ij} = \frac{\mathbf{z}_{ij} \boldsymbol{\Psi} \mathbf{z}_{ij}^\top}{\mathbf{z}_{ij} \boldsymbol{\Psi} \mathbf{z}_{ij}^\top  + s_{ij}^2}
\label{eq:vpc}
\end{equation}

\noindent The VPC is indexed by both $i$ and $j$ because it depends both on the observed dose value $z_{ij}$ and the variance for the log relative risk $s_{ij}^2$. Values for VPC can be expressed as percentage to quantify the proportion of residual variance attributable to heterogeneity. Because the VPC will typically vary for different doses, overlay a LOWESS smother in a scatter plot VPC versus dose levels may help to examine the impact of heterogeneity over the exposure range.

\subsection{Prediction}

Predictions for the combined, or marginal, curve are obtained as in equation~\ref{eq:pred}, where now the $\boldsymbol{\hat \beta}$ coefficients were estimated using the log relative risks as outcome variables rather than the study-specific $\boldsymbol{\hat \beta}_i$. 

\noindent Predictions are also available for study-specific curves. Using the normality distribution for the random-effects, \cite{henderson1959estimation} compute the asymptotic best linear unbiased prediction (BLUP) of the random-effects $\boldsymbol{b}$ as
\begin{equation}
\hat {\mathbf{b}}_i = \hat{\boldsymbol{\Psi}} \mathbf{Z}_i^\top \hat{\boldsymbol{\Sigma}}_i^{-1}\left( \mathbf{y}_i - \mathbf{X}_i\hat{\boldsymbol{\beta}} \right)
\label{eq:blup_os}
\end{equation}

The conditional dose--response coefficients are defined as $\mathbf{X}_i\hat{\boldsymbol{\beta}} + \hat {\mathbf{b}}_i$. Of note, individual curves defined by $p$ parameters can be predicted for those studies reporting $J_i < p$ non-referent relative risks. The BLUP employ the information of the entire distribution of the random-effects to make the best possible prediction.

\subsection{Comparison with two-stage analysis}

Previous methodological articles have oftentimes implemented new methods using the two-stage approach, mainly because of computation reasons. The alternative one-stage approach has been frequently referred to as equivalent and was no further investigated. The tools to assess the goodness-of-fit in \citetalias{discacciati2015goodness} were established using the one-stage framework. We proved in the supplementary material that the two techniques give identical results in a fixed-effects analysis of non-linear curves, not only for the simpler case of a linear trend. In the appendix of \citetalias{crippa2018one}, we extended the equivalence to the setting of non-linear curves for a random-effects model. In order to provide the same point and interval estimates, the study-specific models in the two-stage analysis need to be estimable, i.e. $p \le \min(J_i)$. In practical examples, small discrepancies in $\boldsymbol{\hat \beta}$ and $\widehat{\Var} \left( \boldsymbol{\hat \beta} \right)$ may be related to differences in the optimization methods for the objective functions of the two techniques.
